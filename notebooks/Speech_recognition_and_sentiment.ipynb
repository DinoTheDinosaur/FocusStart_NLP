{
 "cells": [
  {
   "attachments": {
    "http---alphacephei.com-kaldi-models-vosk-model-ru-0.10.zip.url": {
     "undefined": "W0ludGVybmV0U2hvcnRjdXRdDQpVUkw9aHR0cDovL2FscGhhY2VwaGVpLmNvbS9rYWxkaS9tb2RlbHMvdm9zay1tb2RlbC1ydS0wLjEwLnppcA0K"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Привет! Тут мы распознаём \"голосовые\" твиты с отзывами :)\n",
    "### Настройка окружения:\n",
    "1. Установить Kaldi на вашу Linux-машину. **Примечание**: можно не ставить сам Kaldi, а только пакеты *openfst* и *opengrm* из *kaldi/tools*. Смотрите полную инструкцию по установке Updating language model https://alphacephei.com/vosk/adaptation\n",
    "2. Установить wave и vosk: pip install wave vosk\n",
    "\n",
    "### Задания:\n",
    "1. Успешно запустить имеющийся ноутбук\n",
    "2. Скачать предобученную модель для русской речи http://alphacephei.com/kaldi/models/vosk-model-ru-0.10.zip, переименовать извлечённую папку с данными в *model* и расположить её относительно ноутбука в ../\n",
    "3. До вечера четверга записать 6 примеров аудио (прочитать по 3 примера из каждого датасета, по 1 примеру на каждый класс - положительный, отрицательный и нейтральный) & прислать мне :) Аудио должны быть формата моно PCM; пример конвертирования в нужный формат с использованием ffmpeg https://stackoverflow.com/questions/13358287/how-to-convert-any-mp3-file-to-wav-16khz-mono-16bit\n",
    "3. Использовать предобученную модель для распознавания сентимента записанных \"голосовых\" твитов, для этого модифицировать функцию *predict_sentiment*\n",
    "4. Адаптировать языковую модель с помощью тех текстов, которые есть в данных bank и ttk (см. инструкцию https://alphacephei.com/vosk/adaptation). Это делается в командной строке с помощью бинарников из инструментов, которые поставляются вместе с Kaldi![http---alphacephei.com-kaldi-models-vosk-model-ru-0.10.zip.url](attachment:http---alphacephei.com-kaldi-models-vosk-model-ru-0.10.zip.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Импортим нужные библиотеки, обозначаем уровень логирования для vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "\n",
    "SetLogLevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Определяем функцию для распознавания русскоязычной речи в WAV файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_audio(filepath, model_path='../model'):\n",
    "    wf = wave.open(filepath, \"rb\")\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != 'NONE':\n",
    "        return 'ERROR: Аудио должно быть формата WAV mono PCM.'\n",
    "\n",
    "    model = Model(model_path)\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        rec.AcceptWaveform(data)\n",
    "\n",
    "    return json.loads(rec.Result())['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Определяем функцию для распознавания сентимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_sentiment(message):\n",
    "    sentiment = 'neutral'\n",
    "    ### Здесь должен быть ваш код  ###\n",
    "    ### с использованием модели    ###\n",
    "    ### для определения сентимента ###\n",
    "    if 'обожаю' in message:\n",
    "        sentiment = 'positive'\n",
    "    elif 'ненавижу' in message:\n",
    "        sentiment = 'negative'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Пробуем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я обожаю'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_text = recognize_audio('../data/positive_1.wav')\n",
    "positive_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_sentiment(positive_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я обожаю'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text = recognize_audio('../data/positive_1.wav')\n",
    "positive_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_sentiment(positive_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robocall TTS 37",
   "language": "python",
   "name": "tts37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
